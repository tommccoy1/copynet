time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 0 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_0.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 1 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_1.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 2 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_2.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 3 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_3.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 4 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_4.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 5 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_5.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 6 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_6.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 7 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_7.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 8 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_8.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1 > logs/training_curve_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 10 > logs/training_curve_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 20 > logs/training_curve_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 30 > logs/training_curve_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 40 > logs/training_curve_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 50 > logs/training_curve_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 60 > logs/training_curve_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 70 > logs/training_curve_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 80 > logs/training_curve_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 90 > logs/training_curve_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 100 > logs/training_curve_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 110 > logs/training_curve_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 120 > logs/training_curve_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 130 > logs/training_curve_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 140 > logs/training_curve_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 150 > logs/training_curve_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 160 > logs/training_curve_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 170 > logs/training_curve_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 180 > logs/training_curve_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 190 > logs/training_curve_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 200 > logs/training_curve_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 250 > logs/training_curve_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 300 > logs/training_curve_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 350 > logs/training_curve_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 400 > logs/training_curve_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 450 > logs/training_curve_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 500 > logs/training_curve_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 550 > logs/training_curve_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 600 > logs/training_curve_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 650 > logs/training_curve_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 700 > logs/training_curve_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 750 > logs/training_curve_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 800 > logs/training_curve_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 850 > logs/training_curve_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 900 > logs/training_curve_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 950 > logs/training_curve_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1000 > logs/training_curve_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1100 > logs/training_curve_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1200 > logs/training_curve_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1300 > logs/training_curve_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1400 > logs/training_curve_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1500 > logs/training_curve_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1600 > logs/training_curve_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1700 > logs/training_curve_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1800 > logs/training_curve_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1900 > logs/training_curve_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200 --patience 5 --hidden 256 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 2000 > logs/training_curve_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1 > logs/training_curve_tp_transformer_trainsize_1_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 1  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 10 > logs/training_curve_tp_transformer_trainsize_10_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 2  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 20 > logs/training_curve_tp_transformer_trainsize_20_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 3  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 30 > logs/training_curve_tp_transformer_trainsize_30_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 4  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 40 > logs/training_curve_tp_transformer_trainsize_40_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 5  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 50 > logs/training_curve_tp_transformer_trainsize_50_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 6  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 60 > logs/training_curve_tp_transformer_trainsize_60_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 7  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 70 > logs/training_curve_tp_transformer_trainsize_70_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 8  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 80 > logs/training_curve_tp_transformer_trainsize_80_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 9  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 90 > logs/training_curve_tp_transformer_trainsize_90_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 10  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 100 > logs/training_curve_tp_transformer_trainsize_100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 11  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 110 > logs/training_curve_tp_transformer_trainsize_110_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 12  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 120 > logs/training_curve_tp_transformer_trainsize_120_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 13  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 130 > logs/training_curve_tp_transformer_trainsize_130_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 14  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 140 > logs/training_curve_tp_transformer_trainsize_140_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 15  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 150 > logs/training_curve_tp_transformer_trainsize_150_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 16  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 160 > logs/training_curve_tp_transformer_trainsize_160_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 17  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 170 > logs/training_curve_tp_transformer_trainsize_170_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 18  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 180 > logs/training_curve_tp_transformer_trainsize_180_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 19  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 190 > logs/training_curve_tp_transformer_trainsize_190_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 20  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 200 > logs/training_curve_tp_transformer_trainsize_200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 25  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 250 > logs/training_curve_tp_transformer_trainsize_250_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 30  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 300 > logs/training_curve_tp_transformer_trainsize_300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 35  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 350 > logs/training_curve_tp_transformer_trainsize_350_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 40  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 400 > logs/training_curve_tp_transformer_trainsize_400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 45  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 450 > logs/training_curve_tp_transformer_trainsize_450_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 50  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 500 > logs/training_curve_tp_transformer_trainsize_500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 55  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 550 > logs/training_curve_tp_transformer_trainsize_550_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 60  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 600 > logs/training_curve_tp_transformer_trainsize_600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 65  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 650 > logs/training_curve_tp_transformer_trainsize_650_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 70  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 700 > logs/training_curve_tp_transformer_trainsize_700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 75  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 750 > logs/training_curve_tp_transformer_trainsize_750_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 80  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 800 > logs/training_curve_tp_transformer_trainsize_800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 85  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 850 > logs/training_curve_tp_transformer_trainsize_850_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 90  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 900 > logs/training_curve_tp_transformer_trainsize_900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 95  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 950 > logs/training_curve_tp_transformer_trainsize_950_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 100  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1000 > logs/training_curve_tp_transformer_trainsize_1000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 110  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1100 > logs/training_curve_tp_transformer_trainsize_1100_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 120  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1200 > logs/training_curve_tp_transformer_trainsize_1200_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 130  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1300 > logs/training_curve_tp_transformer_trainsize_1300_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 140  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1400 > logs/training_curve_tp_transformer_trainsize_1400_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 150  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1500 > logs/training_curve_tp_transformer_trainsize_1500_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 160  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1600 > logs/training_curve_tp_transformer_trainsize_1600_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 170  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1700 > logs/training_curve_tp_transformer_trainsize_1700_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 180  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1800 > logs/training_curve_tp_transformer_trainsize_1800_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 190  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 1900 > logs/training_curve_tp_transformer_trainsize_1900_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
time python main.py --model tp_transformer  --dataset_prefix length5_ninn_withholding  --batch_size 10 --eval_every 200  --patience 5 --hidden 230 --vocab_size 10 --n_heads 4 --n_layers 2 --filter 256 --random_seed 9 --model_name training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9 --training_size 2000 > logs/training_curve_tp_transformer_trainsize_2000_dataset_length5_ninn_withholding_bs_10_patience_5_hidden_256_230_heads_4_layers_2_filter_256_seed_9.results
